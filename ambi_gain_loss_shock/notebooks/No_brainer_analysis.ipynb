{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for preprocessing the gainloss data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_gainloss(df):\n",
    "    \n",
    "    #drop columns Unnamed, id, AID, HID, session_id, practice, loss_or_reward, instruction_number, est_left_over_right\n",
    "    df = df.drop(['Unnamed: 0', 'id', 'AID', 'HID', 'session_id', 'practice', 'loss_or_reward', 'instruct_number', 'est_left_over_right', 'prop_left', 'prop_right'], axis = 1)\n",
    "    #calculate revealed prop_left and prop_right from revealed tokens\n",
    "    df['prop_left'] = df['revealed_x_l']/(df['revealed_x_l'] + df['revealed_o_l'])\n",
    "    df['prop_right'] = df['revealed_x_r']/(df['revealed_x_r'] + df['revealed_o_r'])\n",
    "    #add column with percentage revealed in ambiguous urn (=1 when both urns are unambiguous) and calculate how many tokens were presented in ambigupus urn (info_ambi) + the sqrt transformation (P)\n",
    "    df['revealed_ambi'] =df[['revealed_left','revealed_right']].min(axis = 1)\n",
    "    df['info'] = df['revealed_ambi']*50\n",
    "    df['P'] = np.sqrt(df['info'])\n",
    "    #indicate whether trial is gain or loss\n",
    "    df['gain'] = (df['mag_left']>0)\n",
    "    #add sections \n",
    "    df['section'] = df['trial_number']\n",
    "    df.loc[df['section'] < 51, 'section'] = 1 \n",
    "    df.loc[df['section'] > 100, 'section'] = 3 \n",
    "    df.loc[df['section'] > 3, 'section'] = 2\n",
    "    \n",
    "    #gainloss_df['sections'] = gainloss_df.loc[gainloss_df['trial_number'] > 50 & gainloss_df['trial_number'] < 101, 'sections'] = 2 \n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to calculate no-brainer performance for each subject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create subset with unambiguous trials for no brainer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_ambi_trials(df):\n",
    "    df = df[df.revealed_ambi == 1]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create variables indicating whether left or right was the better option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def better_choice_gainloss(df):\n",
    "\n",
    "    index = df.index\n",
    "    left_better = []\n",
    "    right_better = []\n",
    "\n",
    "    for i in index:\n",
    "\n",
    "        if df['gain'][i].all() == True:\n",
    "            lb = (df['prop_left'][i]>df['prop_right'][i]) & (df['mag_left'][i]>df['mag_right'][i])\n",
    "            rb = (df['prop_left'][i]<df['prop_right'][i]) & (df['mag_left'][i]<df['mag_right'][i])\n",
    "    \n",
    "        elif df['gain'][i].all() == False:\n",
    "            lb = (df['prop_left'][i]<df['prop_right'][i]) & (df['mag_left'][i]>df['mag_right'][i])\n",
    "            rb = (df['prop_left'][i]>df['prop_right'][i]) & (df['mag_left'][i]<df['mag_right'][i])\n",
    "        \n",
    "        left_better.append(lb)\n",
    "        right_better.append(rb)\n",
    "        \n",
    "    df['left_better']=left_better\n",
    "    df['right_better']=right_better   \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indicate whether the better box was chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def right_choice(df):\n",
    "    df['choseBetter'] = (df['resp'] == 'left') & (df['left_better']== True) | (df['resp'] == 'right') & (df['right_better']==True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep trials that are 'no brainers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keep_nobrainers(df):\n",
    "    df['noBrainer'] = (df['right_better'] != df['left_better'])\n",
    "    df = df[df.noBrainer == True]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vp_perf(df):\n",
    "    df = df['choseBetter'].mean()\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#df['choseBetter'].groupby('sections').mean().add_prefix('mean_')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the online data and check no brainer trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "vp_perform_gainloss_list = []\n",
    "vp_nb_gainloss_list = []\n",
    "vp_list = ['06', '07', '10', '12', '13', '15', '16', '17', '18', '19', '20', '22', '23_2', '25_2', '26_2', '27_2', '28_2', '29', '30']\n",
    "for vp in vp_list:\n",
    "    path = os.path.join(os.getcwd(),'..','data','data_gainloss_logfiles','vp' + vp + '_gainloss_processed.csv')\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    #preprocess data\n",
    "    df=preprocess_gainloss(df)\n",
    "    #store prepocessed data in list that contains data for all subjects (for later analysis)\n",
    "    df_list.append(df)\n",
    "    #create subset with unambiguous trials for no brainer analysis\n",
    "    df = drop_ambi_trials(df)\n",
    "    #create variables indicating whether left or right was the better option\n",
    "    better_choice_gainloss(df)\n",
    "    #add whether the better box was chosen\n",
    "    right_choice(df)\n",
    "    #only keep trials that are 'no brainers'\n",
    "    df = keep_nobrainers(df)\n",
    "    #calculate performance\n",
    "    vp_perform_gainloss = ['vp' + vp, vp_perf(df)]\n",
    "    #store each vp performance in list\n",
    "    vp_perform_gainloss_list.append(vp_perform_gainloss)\n",
    "    #vp performance sectionwise\n",
    "    vp_nb_gainloss = df.groupby('section').mean().add_prefix('gainloss_')[['gainloss_choseBetter']]\n",
    "    vp_nb_gainloss['MID'] = 'vp'+ vp\n",
    "    vp_nb_gainloss_list.append(vp_nb_gainloss)\n",
    "    \n",
    "#Merge dataframe list to single dataframe. \"inner\": Just take columns which exist in all dataframes    \n",
    "gainloss_df = pd.concat(df_list, ignore_index = True, join = 'inner')  \n",
    "#vp_gainloss_perf = pd.concat(vp_performance_list, ignore_index = True, join = 'inner')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[         gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp06\n",
       " 2                    1.000000  vp06\n",
       " 3                    0.960000  vp06,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    1.000000  vp07\n",
       " 2                    0.666667  vp07\n",
       " 3                    1.000000  vp07,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                         1.0  vp10\n",
       " 2                         1.0  vp10\n",
       " 3                         1.0  vp10,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp12\n",
       " 2                        1.00  vp12\n",
       " 3                        0.92  vp12,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp13\n",
       " 2                        1.00  vp13\n",
       " 3                        0.88  vp13,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp15\n",
       " 2                        1.00  vp15\n",
       " 3                        0.92  vp15,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp16\n",
       " 2                        1.00  vp16\n",
       " 3                        0.96  vp16,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp17\n",
       " 2                    1.000000  vp17\n",
       " 3                    1.000000  vp17,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp18\n",
       " 2                    1.000000  vp18\n",
       " 3                    0.960000  vp18,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                        1.00  vp19\n",
       " 2                        1.00  vp19\n",
       " 3                        0.52  vp19,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp20\n",
       " 2                    1.000000  vp20\n",
       " 3                    1.000000  vp20,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    1.000000  vp22\n",
       " 2                    0.666667  vp22\n",
       " 3                    0.880000  vp22,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    0.818182  vp23_2\n",
       " 2                    1.000000  vp23_2\n",
       " 3                    1.000000  vp23_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                         1.0  vp25_2\n",
       " 2                         1.0  vp25_2\n",
       " 3                         1.0  vp25_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    1.000000  vp26_2\n",
       " 2                    1.000000  vp26_2\n",
       " 3                    0.972222  vp26_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                         1.0  vp27_2\n",
       " 2                         1.0  vp27_2\n",
       " 3                         1.0  vp27_2,          gainloss_choseBetter     MID\n",
       " section                              \n",
       " 1                    0.833333  vp28_2\n",
       " 2                    0.666667  vp28_2\n",
       " 3                    0.888889  vp28_2,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp29\n",
       " 2                    0.333333  vp29\n",
       " 3                    0.520000  vp29,          gainloss_choseBetter   MID\n",
       " section                            \n",
       " 1                    0.833333  vp30\n",
       " 2                    1.000000  vp30\n",
       " 3                    0.805556  vp30]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_nb_gainloss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "section1 = df[df.section == 1]\n",
    "section2 = df[df.section == 2]\n",
    "section3 = df[df.section == 3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for shock data\n",
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_shock(df):\n",
    "    \n",
    "    #drop columns Unnamed, id, AID, HID, session_id, practice, loss_or_reward, instruction_number, est_left_over_right\n",
    "    df = df.drop(['br', 'UrnsPresented_duration', 'ChoiceTime_duration', 'ChoiceDisplayed_duration', 'OutcomeDisplayed_duration',\n",
    "                  'ITI_duration', 'OutcomeHistoryDisplayed_duration', 'ShockOutcomeDisplayed_duration', 'ExtraITI_duration',\n",
    "                  'time_urns_presented', 'time_participant_choice_presented', 'token_chosen_presented_time', 'shock_time',\n",
    "                  'resultpicture_time', 'time_ITI_begin', 'time_Extra_ITI_begin', 'choicetime', 'computerchoice_outcome',\n",
    "                  'numberofshocks', 'outcome_chosen', 'numberbin1', 'numberbin2', 'numberbin3', 'numberbin0', 'outcome_intoarray',\n",
    "                  'breaktime', 'length_break', 'FIRST_ITI_start', 'ITI_start', 'UrnsPresented_start',\n",
    "                  'QuestionMark_start', 'ButtonPress_start', 'ChoiceDisplayed_start', 'Outcome_start',\n",
    "                  'OutcomeHistoryDisplayed_start', 'ShockOutcomeDisplay_start', 'Shock_start', 'ExtraITI_start', \n",
    "                  'Trial_starttime', 'p_left', 'p_right'], axis=1)\n",
    "    \n",
    "    #### MATCH TO GAIN/LOSS ####\n",
    "    \n",
    "    #rename variable names to match gain/loss\n",
    "    df.rename(columns={'pr': 'revealed_right', 'pr_left': 'revealed_left', 'magnitude_left': 'mag_left', 'magnitude_right': 'mag_right', 'time_button_press': 'reaction_time', 'participantsbet': 'resp', 'outcome': 'mag_outcome', 'trialnumber': 'trial_number', 'result_given1in10': 'five_trials_outcome'}, inplace=True)\n",
    "    #rename values to match gain/loss\n",
    "    df['resp'] = df['resp'].map({'bet_left': 'left', 'bet_right': 'right'})\n",
    "    df['outcome'] = df['mag_outcome']\n",
    "    df.loc[df['outcome'] > 0, 'outcome'] = 'X' \n",
    "    df.loc[df['outcome'] == 0, 'outcome'] = 'O'\n",
    "    #add variable revealed_x_right etc from colors\n",
    "    \n",
    "    #calculate revealed prop_left and prop_right from revealed tokens\n",
    "    df['prop_left'] = df['revealed_x_l']/(df['revealed_x_l'] + df['revealed_o_l'])\n",
    "    df['prop_right'] = df['revealed_x_r']/(df['revealed_x_r'] + df['revealed_o_r'])\n",
    "    #add column with percentage revealed in ambiguous urn (=1 when both urns are unambiguous) and calculate how many tokens were presented in ambigupus urn (info_ambi) + the sqrt transformation (P)\n",
    "    df['revealed_ambi'] = df[['revealed_left','revealed_right']].min(axis = 1)\n",
    "    df['info'] = df['revealed_ambi']*50\n",
    "    df['P'] = np.sqrt(df['info'])\n",
    "    #indicate whether trial is shock\n",
    "    df['shock'] = (df['mag_left']>0)\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in colors with first 50 elements of a line representing the tokens in right box, last 50 elements of left box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addTokens(df):\n",
    "    \n",
    "    path = os.path.join(os.getcwd(),'..','data','data_shock_mscl','colours_Behaviour_Analysis.txt')\n",
    "    tokens_df = pd.read_csv(path, sep=\",\", skiprows=[0], header=None)\n",
    "    tokens_df[0] = tokens_df[0].str.replace('{','')\n",
    "    tokens_df[99] = tokens_df[99].str.replace('}', '')\n",
    "    tokens_df = tokens_df.drop(tokens_df.columns[100], axis=1)\n",
    "    tokens_df = tokens_df.astype('int64')\n",
    "    freq_right = tokens_df.iloc[:, :50].apply(pd.value_counts, axis=1).fillna(0)\n",
    "    freq_left = tokens_df.iloc[:, 50:].apply(pd.value_counts, axis=1).fillna(0)\n",
    "    \n",
    "    df['revealed_x_r'] = freq_right.loc[:, 0]\n",
    "    df['revealed_o_r'] = freq_right.loc[:, 1]\n",
    "\n",
    "    df['revealed_x_l'] = freq_left.loc[:, 0]\n",
    "    df['revealed_o_l'] = freq_left.loc[:, 1]\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def better_choice_shock(df):\n",
    "    \n",
    "    lb = (df['prop_left']<df['prop_right']) & (df['mag_left']<df['mag_right'])\n",
    "    rb = (df['prop_left']>df['prop_right']) & (df['mag_left']>df['mag_right'])\n",
    "    \n",
    "    #left_better.append(lb)\n",
    "    #right_better.append(rb)\n",
    "        \n",
    "    df['left_better']=lb\n",
    "    df['right_better']=rb\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the shock data\n",
    "- one dataframe per subject\n",
    "- match column names to match the gain/loss names.\n",
    "\n",
    "- read in coloursblabl_9_14_17.txt, count 0, 1, 2 and first 50 right box, last 50 are left box, check if 0 correspond to Os\n",
    "    - read file line by line\n",
    "    -with file.txt\n",
    "    -readline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Hanna\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "vp_list = ['06', '07', '10', '12', '13', '15', '16', '17', '18', '19', '20', '22', '23', '25', '26', '27', '28', '29', '30']\n",
    "vp_perform_shock_list = []\n",
    "vp_nb_shock_list = []\n",
    "section_list = ['1', '2', '3']\n",
    "for vp in vp_list:\n",
    "    df = []\n",
    "    for sec in section_list:\n",
    "        path = os.path.join(os.getcwd(),'..','data','data_behavioral','Expt1Pain_Behaviour_vp' + vp + '_' + sec + '.txt')\n",
    "        df_dummy = pd.read_csv(path, sep=\"\\t\", skiprows = [0])\n",
    "        df_dummy['MID'] = 'vp'+ vp\n",
    "        df_dummy['section'] = sec\n",
    "        df_dummy.columns = df_dummy.columns.str.replace(' ','')\n",
    "        df.append(df_dummy)\n",
    "    #create a df that contains data from all sections    \n",
    "    df = pd.concat(df, ignore_index = True, join = 'inner')\n",
    "    df = addTokens(df)\n",
    "    #preprocess shock data\n",
    "    df = preprocess_shock(df)\n",
    "    #store prepocessed data in list that contains data for all subjects (for later analysis)\n",
    "    df_list.append(df)\n",
    "    #create subset with unambiguous trials for no brainer analysis\n",
    "    df = drop_ambi_trials(df)\n",
    "    #create variables indicating whether left or right was the better option\n",
    "    df = better_choice_shock(df)\n",
    "    #add whether the better box was chosen\n",
    "    df = right_choice(df)\n",
    "    #only keep trials that are 'no brainers'\n",
    "    df = keep_nobrainers(df)\n",
    "    #calculate performance\n",
    "    vp_perform_shock = ['vp' + vp, vp_perf(df)]\n",
    "    #store each vp performance in list\n",
    "    vp_perform_shock_list.append(vp_perform_shock)\n",
    "    #vp performance sectionwise\n",
    "    vp_nb_shock = df.groupby('section').mean().add_prefix('shock_')[['shock_choseBetter']]\n",
    "    vp_nb_shock['MID'] = 'vp'+ vp\n",
    "    vp_nb_shock_list.append(vp_nb_shock)\n",
    "\n",
    "#create complete df for shock condition with all vps        \n",
    "shock_df = pd.concat(df_list, ignore_index = True, join = 'inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vp_perform_gainloss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vp_nb_gainloss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vp_perform_shock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vp_nb_shock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#section1 = df[df.section == '1']\n",
    "#section2 = df[df.section == '2']\n",
    "#section3 = df[df.section == '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[['mag_left', 'mag_right', 'resp', 'prop_left', 'prop_right', 'left_better', 'right_better', 'choseBetter']]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
